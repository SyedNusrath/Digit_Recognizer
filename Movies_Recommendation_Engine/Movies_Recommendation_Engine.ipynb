{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Recommendation Engine\n",
    "\n",
    "### Syed Nusrath (Pratice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rapid growth of data collection has led to a new era of information. Data is being used to create more efficient systems and this is where Recommendation Systems come into play.  Recommendation Systems are a type of **information filtering systems** as they improve the quality of search results and provides items that are more relevant to the search item or are realted to the search history of the user.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are used to predict the **rating** or **preference** that a user would give to an item. Almost every major tech company has applied them in some form or the other: Amazon uses it to suggest products to customers, YouTube uses it to decide which video to play next on autoplay, and Facebook uses it to recommend pages to like and people to follow. \n",
    "Moreover,  companies like Netflix and Spotify  depend highly on the effectiveness of their recommendation engines for their business and sucees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.kinja-img.com/gawker-media/image/upload/s--e3_2HgIC--/c_scale,f_auto,fl_progressive,q_80,w_800/1259003599478673704.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel we'll be building a baseline Movie Recommendation System using [TMDB 5000 Movie Dataset](https://www.kaggle.com/tmdb/tmdb-movie-metadata). For novices like me this kernel will pretty much serve as a foundation in recommendation systems and will provide you with something to start with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So let's go!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are basically three types of recommender systems:-\n",
    "\n",
    "> *  **Demographic Filtering**- They offer generalized recommendations to every user, based on movie popularity and/or genre. The System recommends the same movies to users with similar demographic features. Since each user is different , this approach is considered to be too simple. The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *  **Content Based Filtering**- They suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *  **Collaborative Filtering**- This system matches persons with similar interests and provides recommendations based on this matching. Collaborative filters do not require item metadata like its content-based counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv(r'C:\\Users\\syed.nusrath\\Desktop\\EY_Learning\\ML\\GitRep\\Kaggle_Data\\the-movies-dataset\\tmdb-5000-movie-dataset\\tmdb_5000_credits.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\syed.nusrath\\Desktop\\EY_Learning\\ML\\GitRep\\Kaggle_Data\\the-movies-dataset\\tmdb-5000-movie-dataset\\tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset contains the following features:-\n",
    "\n",
    "* movie_id - A unique identifier for each movie.\n",
    "* cast - The name of lead and supporting actors.\n",
    "* crew - The name of Director, Editor, Composer, Writer etc.\n",
    "\n",
    "The second dataset has the following features:- \n",
    "\n",
    "* budget - The budget in which the movie was made.\n",
    "* genre - The genre of the movie, Action, Comedy ,Thriller etc.\n",
    "* homepage - A link to the homepage of the movie.\n",
    "* id - This is infact the movie_id as in the first dataset.\n",
    "* keywords - The keywords or tags related to the movie.\n",
    "* original_language - The language in which the movie was made.\n",
    "* original_title - The title of the movie before translation or adaptation.\n",
    "* overview - A brief description of the movie.\n",
    "* popularity - A numeric quantity specifying the movie popularity.\n",
    "* production_companies - The production house of the movie.\n",
    "* production_countries - The country in which it was produced.\n",
    "* release_date - The date on which it was released.\n",
    "* revenue - The worldwide revenue generated by the movie.\n",
    "* runtime - The running time of the movie in minutes.\n",
    "* status - \"Released\" or \"Rumored\".\n",
    "* tagline - Movie's tagline.\n",
    "* title - Title of the movie.\n",
    "* vote_average -  average ratings the movie recieved.\n",
    "* vote_count - the count of votes recieved.\n",
    "\n",
    "Let's join the two dataset on the 'id' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.columns= ['id','title','cast','crew']\n",
    "df2 = df2.merge(df1, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title_x</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>title_y</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>[{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...</td>\n",
       "      <td>[{\"credit_id\": \"52fe48009251416c750aca23\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[{\"cast_id\": 4, \"character\": \"Captain Jack Spa...</td>\n",
       "      <td>[{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>[{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...</td>\n",
       "      <td>[{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>[{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...</td>\n",
       "      <td>[{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>...</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>[{\"cast_id\": 5, \"character\": \"John Carter\", \"c...</td>\n",
       "      <td>[{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3            http://www.thedarkknightrises.com/   49026   \n",
       "4          http://movies.disney.com/john-carter   49529   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "3  Following the death of District Attorney Harve...  112.312950   \n",
       "4  John Carter is a war-weary, former military ca...   43.926995   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "\n",
       "                         ...                         runtime  \\\n",
       "0                        ...                           162.0   \n",
       "1                        ...                           169.0   \n",
       "2                        ...                           148.0   \n",
       "3                        ...                           165.0   \n",
       "4                        ...                           132.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "3           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "3                                 The Legend Ends   \n",
       "4            Lost in our world, found in another.   \n",
       "\n",
       "                                    title_x vote_average vote_count  \\\n",
       "0                                    Avatar          7.2      11800   \n",
       "1  Pirates of the Caribbean: At World's End          6.9       4500   \n",
       "2                                   Spectre          6.3       4466   \n",
       "3                     The Dark Knight Rises          7.6       9106   \n",
       "4                               John Carter          6.1       2124   \n",
       "\n",
       "                                    title_y  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...   \n",
       "1  [{\"cast_id\": 4, \"character\": \"Captain Jack Spa...   \n",
       "2  [{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...   \n",
       "3  [{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...   \n",
       "4  [{\"cast_id\": 5, \"character\": \"John Carter\", \"c...   \n",
       "\n",
       "                                                crew  \n",
       "0  [{\"credit_id\": \"52fe48009251416c750aca23\", \"de...  \n",
       "1  [{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...  \n",
       "2  [{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...  \n",
       "3  [{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...  \n",
       "4  [{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Demographic Filtering** -\n",
    "   Before getting started with this  -\n",
    "* we need a metric to score or rate movie \n",
    "* Calculate the score for every movie \n",
    "* Sort the scores and recommend the best rated movie to the users.\n",
    "\n",
    "We can use the average ratings of the movie as the score but using this won't be fair enough since a movie with 8.9 average rating and only 3 votes cannot be considered better than the movie with 7.8 as as average rating but 40 votes.\n",
    "So, I'll be using IMDB's weighted rating (wr) which is given as :-\n",
    "\n",
    "![](https://image.ibb.co/jYWZp9/wr.png)\n",
    "where,\n",
    "* v is the number of votes for the movie;\n",
    "* m is the minimum votes required to be listed in the chart;\n",
    "* R is the average rating of the movie; And\n",
    "* C is the mean vote across the whole report\n",
    "\n",
    "We already have v(**vote_count**) and R (**vote_average**) and C can be calculated as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.092171559442011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = df2['vote_average'].mean()\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the mean rating for all the movies is approx 6 on a scale of 10.The next step is to determine an appropriate value for m, the minimum votes required to be listed in the chart. We will use 90th percentile as our cutoff. In other words, for a movie to feature in the charts, it must have more votes than at least 90% of the movies in the list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838.4000000000015"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = df2['vote_count'].quantile(0.9)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can filter out the movies that qualify for the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_movies = df2.copy().loc[df2['vote_count']>=m]\n",
    "q_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 481 movies which qualify to be in this list. Now, we need to calculate our metric for each qualified movie. To do this, we will define a function, **weighted_rating()** and define a new feature **score**, of which we'll calculate the value by applying this function to our DataFrame of qualified movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_rating(df, m=m, C=C):\n",
    "    v = df['vote_count']\n",
    "    R = df['vote_average']\n",
    "#     Calucalated based on IMDB Formula\n",
    "    return (v/(v+m)*R) + (m/(v+m)*C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's sort the DataFrame based on the score feature and output the title, vote count, vote average and weighted rating or score of the top 10 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>8205</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.059258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>9413</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.939256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>12002</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.920020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8428</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.904645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Inception</td>\n",
       "      <td>13752</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.863239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>5893</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.851236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>10867</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.809479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>7927</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.803188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8064</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.727243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>5879</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.697884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title_x  vote_count  vote_average  \\\n",
       "1881                       The Shawshank Redemption        8205           8.5   \n",
       "662                                      Fight Club        9413           8.3   \n",
       "65                                  The Dark Knight       12002           8.2   \n",
       "3232                                   Pulp Fiction        8428           8.3   \n",
       "96                                        Inception       13752           8.1   \n",
       "3337                                  The Godfather        5893           8.4   \n",
       "95                                     Interstellar       10867           8.1   \n",
       "809                                    Forrest Gump        7927           8.2   \n",
       "329   The Lord of the Rings: The Return of the King        8064           8.1   \n",
       "1990                        The Empire Strikes Back        5879           8.2   \n",
       "\n",
       "         score  \n",
       "1881  8.059258  \n",
       "662   7.939256  \n",
       "65    7.920020  \n",
       "3232  7.904645  \n",
       "96    7.863239  \n",
       "3337  7.851236  \n",
       "95    7.809479  \n",
       "809   7.803188  \n",
       "329   7.727243  \n",
       "1990  7.697884  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort movies based on score calculated above\n",
    "q_movies = q_movies.sort_values('score',ascending=False)\n",
    "\n",
    "# Print top 10 movies\n",
    "q_movies[['title_x', 'vote_count', 'vote_average', 'score']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray! We have made our first(though very basic) recommender. Under the Trending Now tab of these systems we find movies that are very popular and they can just be obtained by sorting the dataset by the popularity column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Popular Movies')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy8AAAEWCAYAAABvx6h8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiR1guFFkiRJUif8/3sRGBwa6Fz/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262d8e88588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pop = df2.sort_values('popularity',ascending=False)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.barh(pop['title_x'].head(6),pop['popularity'].head(6), align='center',\n",
    "        color='skyblue')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Popularity\")\n",
    "plt.title(\"Popular Movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now something to keep in mind is that these demographic recommender provide a general chart of recommended movies to all the users. They are not sensitive to the interests and tastes of a particular user. This is when we move on to a more refined system- Content Basesd Filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Content Based Filtering**\n",
    "In this recommender system the content of the movie (overview, cast, crew, keyword, tagline etc) is used to find its similarity with other movies. Then the movies that are most likely to be similar are recommended.\n",
    "\n",
    "![](https://image.ibb.co/f6mDXU/conten.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot description based Recommender**\n",
    "\n",
    "We will compute pairwise similarity scores for all movies based on their plot descriptions and recommend movies based on that similarity score. The plot description is given in the **overview** feature of our dataset. \n",
    "Let's take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    In the 22nd century, a paraplegic Marine is di...\n",
       "1    Captain Barbossa, long believed to be dead, ha...\n",
       "2    A cryptic message from Bond’s past sends him o...\n",
       "3    Following the death of District Attorney Harve...\n",
       "4    John Carter is a war-weary, former military ca...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['overview'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any of you who has done even a  bit of text processing before knows we need to convert the word vector of each overview.\n",
    "Now we'll compute Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each overview.\n",
    "\n",
    "Now if you are wondering what is term frequency , it is the relative frequency of a word in a document and is given as\n",
    "   **(term instances/total instances)**.\n",
    "Inverse Document Frequency is the relative count of documents containing the term is given as \n",
    "**log(number of documents/documents with term)**\n",
    "The overall importance of each word to the documents in which they appear is equal to **TF * IDF**\n",
    "\n",
    "This will give you a matrix where each column represents a word in the overview vocabulary (all the words that appear in at least one document) and each column represents a movie, as before.This is done to reduce the importance of words that occur frequently in plot overviews and therefore, their significance in computing the final similarity score.\n",
    "\n",
    "Fortunately, scikit-learn gives you a built-in TfIdfVectorizer class that produces the TF-IDF matrix in a couple of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4803, 20978)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  import tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Replace NaN with an empty string\n",
    "df2['overview'] = df2['overview'].fillna(\"\")\n",
    " \n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df2['overview'])\n",
    "\n",
    "# Output and shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that over 20,000 different words were used to describe the 4800 movies in our dataset.\n",
    "\n",
    "With this matrix in hand, we can now compute a similarity score. There are several candidates for this; such as the euclidean, the Pearson and the [cosine similarity scores](https://en.wikipedia.org/wiki/Cosine_similarity). There is no right answer to which score is the best. Different scores work well in different scenarios and it is often a good idea to experiment with different metrics.\n",
    "\n",
    "We will be using the cosine similarity to calculate a numeric quantity that denotes the similarity between two movies. We use the cosine similarity score since it is independent of magnitude and is relatively easy and fast to calculate. Mathematically, it is defined as follows:\n",
    "![](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have used the TF-IDF vectorizer, calculating the dot product will directly give us the cosine similarity score. Therefore, we will use sklearn's **linear_kernel()** instead of cosine_similarities() since it is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute Cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix,tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define a function that takes in a movie title as an input and outputs a list of the 10 most similar movies. Firstly, for this, we need a reverse mapping of movie titles and DataFrame indices. In other words, we need a mechanism to identify the index of a movie in our metadata DataFrame, given its title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df2.index , index=df2['title_x']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a good position to define our recommendation function. These are the following steps we'll follow :-\n",
    "* Get the index of the movie given its title.\n",
    "* Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position and the second is the similarity score.\n",
    "* Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n",
    "* Get the top 10 elements of this list. Ignore the first element as it refers to self (the movie most similar to a particular movie is the movie itself).\n",
    "* Return the titles corresponding to the indices of the top elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df2['title_x'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65                              The Dark Knight\n",
       "299                              Batman Forever\n",
       "428                              Batman Returns\n",
       "1359                                     Batman\n",
       "3854    Batman: The Dark Knight Returns, Part 2\n",
       "119                               Batman Begins\n",
       "2507                                  Slow Burn\n",
       "9            Batman v Superman: Dawn of Justice\n",
       "1181                                        JFK\n",
       "210                              Batman & Robin\n",
       "Name: title_x, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Dark Knight Rises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7               Avengers: Age of Ultron\n",
       "3144                            Plastic\n",
       "1715                            Timecop\n",
       "4124                 This Thing of Ours\n",
       "3311              Thank You for Smoking\n",
       "3033                      The Corruptor\n",
       "588     Wall Street: Money Never Sleeps\n",
       "2136         Team America: World Police\n",
       "1468                       The Fountain\n",
       "1286                        Snowpiercer\n",
       "Name: title_x, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Avengers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our system has done a decent job of finding movies with similar plot descriptions, the quality of recommendations is not that great. \"The Dark Knight Rises\" returns all Batman movies while it is more likely that the people who liked that movie are more inclined to enjoy other Christopher Nolan movies. This is something that cannot be captured by the present system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Credits, Genres and Keywords Based Recommender**\n",
    "It goes without saying that the quality of our recommender would be increased with the usage of better metadata. That is exactly what we are going to do in this section. We are going to build a recommender based on the following metadata: the 3 top actors, the director, related genres and the movie plot keywords.\n",
    "\n",
    "From the cast, crew and keywords features, we need to extract the three most important actors, the director and the keywords associated with that movie. Right now, our data is present in the form of \"stringified\" lists , we need to convert it into a safe and usable structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the stringified features into their corresponding python objects\n",
    "from ast import literal_eval\n",
    "\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll write functions that will help us to extract the required information from each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the Director name from the crew's feature. If director is not listed, return NaN\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the list top 3 elements or entire list; whichever is more.\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
    "df2['director'] = df2['crew'].apply(get_director)\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(get_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>cast</th>\n",
       "      <th>director</th>\n",
       "      <th>keywords</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>[Sam Worthington, Zoe Saldana, Sigourney Weaver]</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>[culture clash, future, space war]</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[Johnny Depp, Orlando Bloom, Keira Knightley]</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>[ocean, drug abuse, exotic island]</td>\n",
       "      <td>[Adventure, Fantasy, Action]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>[Daniel Craig, Christoph Waltz, Léa Seydoux]</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>[spy, based on novel, secret agent]</td>\n",
       "      <td>[Action, Adventure, Crime]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title_x  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "\n",
       "                                               cast        director  \\\n",
       "0  [Sam Worthington, Zoe Saldana, Sigourney Weaver]   James Cameron   \n",
       "1     [Johnny Depp, Orlando Bloom, Keira Knightley]  Gore Verbinski   \n",
       "2      [Daniel Craig, Christoph Waltz, Léa Seydoux]      Sam Mendes   \n",
       "\n",
       "                              keywords                        genres  \n",
       "0   [culture clash, future, space war]  [Action, Adventure, Fantasy]  \n",
       "1   [ocean, drug abuse, exotic island]  [Adventure, Fantasy, Action]  \n",
       "2  [spy, based on novel, secret agent]    [Action, Adventure, Crime]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the new features of the first 3 films\n",
    "df2[['title_x', 'cast', 'director', 'keywords', 'genres']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to convert the names and keyword instances into lowercase and strip all the spaces between them. This is done so that our vectorizer doesn't count the Johnny of \"Johnny Depp\" and \"Johnny Galecki\" as the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert all strings to lower case and strip names of spaces\n",
    "def clean_data(x):\n",
    "    if isinstance(x,list):\n",
    "        return [str.lower(i.replace(\" \",\"\")) for i in x]\n",
    "    else:\n",
    "    #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply clean_data function to your features.\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to create our \"metadata soup\", which is a string that contains all the metadata that we want to feed to our vectorizer (namely actors, director and keywords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "df2['soup'] = df2.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are the same as what we did with our plot description based recommender. One important difference is that we use the **CountVectorizer()** instead of TF-IDF. This is because we do not want to down-weight the presence of an actor/director if he or she has acted or directed in relatively more movies. It doesn't make much intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(df2['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset index of our main DataFrame and construct reverse mapping as before\n",
    "df2 = df2.reset_index()\n",
    "indices = pd.Series(df2.index, index=df2['title_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reuse our **get_recommendations()** function by passing in the new **cosine_sim2** matrix as your second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65               The Dark Knight\n",
       "119                Batman Begins\n",
       "4638    Amidst the Devil's Wings\n",
       "1196                The Prestige\n",
       "3073           Romeo Is Bleeding\n",
       "3326              Black November\n",
       "1503                      Takers\n",
       "1986                      Faster\n",
       "303                     Catwoman\n",
       "747               Gangster Squad\n",
       "Name: title_x, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Dark Knight Rises', cosine_sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867      The Godfather: Part III\n",
       "2731      The Godfather: Part II\n",
       "4638    Amidst the Devil's Wings\n",
       "2649           The Son of No One\n",
       "1525              Apocalypse Now\n",
       "1018             The Cotton Club\n",
       "1170     The Talented Mr. Ripley\n",
       "1209               The Rainmaker\n",
       "1394               Donnie Brasco\n",
       "1850                    Scarface\n",
       "Name: title_x, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Godfather', cosine_sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our recommender has been successful in capturing more information due to more metadata and has given us (arguably) better recommendations. It is more likely that Marvels or DC comics fans will like the movies of the same production house. Therefore, to our features above we can add production_company . We can also increase the weight of the director , by adding the feature multiple times in the soup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collaborative Filtering**\n",
    "\n",
    "Our content based engine suffers from some severe limitations. It is only capable of suggesting movies which are close to a certain movie. That is, it is not capable of capturing tastes and providing recommendations across genres.\n",
    "\n",
    "Also, the engine that we built is not really personal in that it doesn't capture the personal tastes and biases of a user. Anyone querying our engine for recommendations based on a movie will receive the same recommendations for that movie, regardless of who she/he is.\n",
    "\n",
    "Therefore, in this section, we will use a technique called Collaborative Filtering to make recommendations to Movie Watchers.\n",
    "It is basically of two types:-\n",
    "\n",
    "*  **User based filtering**-  These systems recommend products to a user that similar users have liked. For measuring the similarity between two users we can either use pearson correlation or cosine similarity.\n",
    "This filtering technique can be illustrated with an example. In the following matrixes, each row represents a user, while the columns correspond to different movies except the last one which records the similarity between that user and the target user. Each cell represents the rating that the user gives to that movie. Assume user E is the target.\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*9NBFo4AUQABKfoUOpE3F8Q.png)\n",
    "\n",
    "Since user A and F do not share any movie ratings in common with user E, their similarities with user E are not defined in Pearson Correlation. Therefore, we only need to consider user B, C, and D. Based on Pearson Correlation, we can compute the following similarity.\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*jZIMJzKM1hKTFftHfcSxRw.png)\n",
    "\n",
    "From the above table we can see that user D is very different from user E as the Pearson Correlation between them is negative. He rated Me Before You higher than his rating average, while user E did the opposite. Now, we can start to fill in the blank for the movies that user E has not rated based on other users.\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*9TC6BrfxYttJwiATFAIFBg.png)\n",
    "\n",
    "Although computing user-based CF is very simple, it suffers from several problems. One main issue is that users’ preference can change over time. It indicates that precomputing the matrix based on their neighboring users may lead to bad performance. To tackle this problem, we can apply item-based CF.\n",
    "\n",
    "* **Item Based Collaborative Filtering** - Instead of measuring the similarity between users, the item-based CF recommends items based on their similarity with the items that the target user rated. Likewise, the similarity can be computed with Pearson Correlation or Cosine Similarity. The major difference is that, with item-based collaborative filtering, we fill in the blank vertically, as oppose to the horizontal manner that user-based CF does. The following table shows how to do so for the movie Me Before You.\n",
    "![](https://cdn-images-1.medium.com/max/1000/1*LqFnWb-cm92HoMYBL840Ew.png)\n",
    "\n",
    "It successfully avoids the problem posed by dynamic user preference as item-based CF is more static. However, several problems remain for this method. First, the main issue is ***scalability***. The computation grows with both the customer and the product. The worst case complexity is O(mn) with m users and n items. In addition, ***sparsity*** is another concern. Take a look at the above table again. Although there is only one user that rated both Matrix and Titanic rated, the similarity between them is 1. In extreme cases, we can have millions of users and the similarity between two fairly different movies could be very high simply because they have similar rank for the only user who ranked them both.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Single Value Decomposition**\n",
    "One way to handle the scalability and sparsity issue created by CF is to leverage a **latent factor model** to capture the similarity between users and items. Essentially, we want to turn the recommendation problem into an optimization problem. We can view it as how good we are in predicting the rating for items given a user. One common metric is Root Mean Square Error (RMSE). **The lower the RMSE, the better the performance**.\n",
    "\n",
    "Now talking about latent factor you might be wondering what is it ?It is a broad idea which describes a property or concept that a user or an item have. For instance, for music, latent factor can refer to the genre that the music belongs to. SVD decreases the dimension of the utility matrix by extracting its latent factors. Essentially, we map each user and each item into a latent space with dimension r. Therefore, it helps us better understand the relationship between users and items as they become directly comparable. The below figure illustrates this idea.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*GUw90kG2ltTd2k_iv3Vo0Q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now enough said , let's see how to implement this.\n",
    "Since the dataset we used before did not have userId(which is necessary for collaborative filtering) let's load another dataset. We'll be using the [**Surprise** ](https://surprise.readthedocs.io/en/stable/index.html) library to implement SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Reader, Dataset, SVD, evaluate\n",
    "reader = Reader()\n",
    "ratings = pd.read_csv(r'C:\\Users\\syed.nusrath\\Desktop\\EY_Learning\\ML\\GitRep\\Kaggle_Data\\the-movies-dataset/ratings_small.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this dataset movies are rated on a scale of 5 unlike the earlier one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "data.split(n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syed.nusrath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\surprise\\evaluate.py:66: UserWarning: The evaluate() method is deprecated. Please use model_selection.cross_validate() instead.\n",
      "  'model_selection.cross_validate() instead.', UserWarning)\n",
      "C:\\Users\\syed.nusrath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\surprise\\dataset.py:193: UserWarning: Using data.split() or using load_from_folds() without using a CV iterator is now deprecated. \n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.8958\n",
      "MAE:  0.6885\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.8983\n",
      "MAE:  0.6903\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.8997\n",
      "MAE:  0.6938\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.8895\n",
      "MAE:  0.6862\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.9027\n",
      "MAE:  0.6972\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.8972\n",
      "Mean MAE : 0.6912\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'mae': [0.688476657367047,\n",
       "                             0.6902893533810236,\n",
       "                             0.6938068174119216,\n",
       "                             0.6861503624369455,\n",
       "                             0.6971995920144893],\n",
       "                            'rmse': [0.8958150129420518,\n",
       "                             0.898251804158187,\n",
       "                             0.8996953773625775,\n",
       "                             0.8895191940296293,\n",
       "                             0.9026943967303052]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "evaluate(svd, data, measures=['RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a mean Root Mean Sqaure Error of 0.89 approx which is more than good enough for our case. Let us now train on our dataset and arrive at predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x262fe3b5c18>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick user with user Id 1 and check the ratings she/he has given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1339</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1260759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2193</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2455</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2968</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1260759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3671</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "0        1       31     2.5  1260759144\n",
       "1        1     1029     3.0  1260759179\n",
       "2        1     1061     3.0  1260759182\n",
       "3        1     1129     2.0  1260759185\n",
       "4        1     1172     4.0  1260759205\n",
       "5        1     1263     2.0  1260759151\n",
       "6        1     1287     2.0  1260759187\n",
       "7        1     1293     2.0  1260759148\n",
       "8        1     1339     3.5  1260759125\n",
       "9        1     1343     2.0  1260759131\n",
       "10       1     1371     2.5  1260759135\n",
       "11       1     1405     1.0  1260759203\n",
       "12       1     1953     4.0  1260759191\n",
       "13       1     2105     4.0  1260759139\n",
       "14       1     2150     3.0  1260759194\n",
       "15       1     2193     2.0  1260759198\n",
       "16       1     2294     2.0  1260759108\n",
       "17       1     2455     2.5  1260759113\n",
       "18       1     2968     1.0  1260759200\n",
       "19       1     3671     3.0  1260759117"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings['userId'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=302, r_ui=3, est=2.760353638160817, details={'was_impossible': False})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(1, 302, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For movie with ID 302, we get an estimated prediction of **2.618**. One startling feature of this recommender system is that it doesn't care what the movie is (or what it contains). It works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion** \n",
    "We create recommenders using demographic , content- based and collaborative filtering. While demographic filtering is very elemantary and cannot be used practically, **Hybrid Systems** can take advantage of content-based and collaborative filtering as the two approaches are proved to be almost complimentary.\n",
    "This model was very baseline and only provides a fundamental framework to start with.\n",
    "\n",
    "I would like to mention some excellent refereces that I learned from\n",
    "1. [https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75](https://hackernoon.com/introduction-to-recommender-system-part-1-collaborative-filtering-singular-value-decomposition-44c9659c5e75)\n",
    "2. [https://www.kaggle.com/rounakbanik/movie-recommender-systems](https://www.kaggle.com/rounakbanik/movie-recommender-systems)\n",
    "3. [http://trouvus.com/wp-content/uploads/2016/03/A-hybrid-movie-recommender-system-based-on-neural-networks.pdf](http://trouvus.com/wp-content/uploads/2016/03/A-hybrid-movie-recommender-system-based-on-neural-networks.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
